{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/afizs/ml/blob/master/Use%20Cases/Transaction_Fraud_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36QBl1x7vdQT"
      },
      "source": [
        "## How-to guide for Transaction Fraud use-case on Abacus.AI platform\n",
        "\n",
        "This notebook provides you with a hands on environment to build a  model using the Abacus.AI Python Client Library.\n",
        "\n",
        "We'll be using the [Credit Card Fraud Transactions Dataset](https://s3.amazonaws.com/realityengines.exampledatasets/fraud_transactions/creditcard.csv), which contains attributes of a transaction made through a given credit card and the class of transaction fraud that took place. We will predict the class of fraud that occurs for a transaction with specified attributes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25VDJQKFxbti"
      },
      "source": [
        "1. Install the Abacus.AI library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVksulmJnO_n"
      },
      "outputs": [],
      "source": [
        "!pip install abacusai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9P6NbNaxkAt"
      },
      "source": [
        "We'll also import pandas and pprint tools for neat visualization in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7QqPII_nvjv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # A tool we'll use to download and preview CSV files\n",
        "import pprint # A tool to pretty print dictionary outputs\n",
        "pp = pprint.PrettyPrinter(indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuU1oAhOxpI8"
      },
      "source": [
        "2. Add your Abacus.AI [API Key](https://abacus.ai/app/profile/apikey) generated using the API dashboard as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU5HqoYbnxlh"
      },
      "outputs": [],
      "source": [
        "#@title Abacus.AI API Key\n",
        "\n",
        "api_key = ''  #@param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MenAFoezxvnI"
      },
      "source": [
        "3. Import the Abacus.AI library and instantiate a client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8RB3YbKnx7i"
      },
      "outputs": [],
      "source": [
        "from abacusai import ApiClient\n",
        "client = ApiClient(api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvCc8UMQx3v9"
      },
      "source": [
        "## 1. Create a Project\n",
        "\n",
        "Abacus.AI projects are containers that have datasets and trained models. By specifying a business **Use Case**, Abacus.AI tailors the deep learning algorithms to produce the best performing model possible for your data.\n",
        "\n",
        "We'll call the `list_use_cases` method to retrieve a list of the available Use Cases currently available on the Abacus.AI platform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z7AF_nknzVm"
      },
      "outputs": [],
      "source": [
        "client.list_use_cases()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSuVCUSnyQvy"
      },
      "source": [
        "For this workshop, we're going to create a fraud prediction model using the Credit Card Transactions dataset. The 'FRAUD_TRANSACTIONS' use case is best tailored for this situation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oaFcsLqn0ZK"
      },
      "outputs": [],
      "source": [
        "#@title Abacus.AI Use Case\n",
        "\n",
        "use_case = 'FRAUD_TRANSACTIONS'  #@param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TZXIyA8z1bZ"
      },
      "source": [
        "By calling the `describe_use_case_requirements` method we can view what datasets are required for this use_case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9kLFFYTn7Az"
      },
      "outputs": [],
      "source": [
        "for requirement in client.describe_use_case_requirements(use_case):\n",
        "  pp.pprint(requirement.to_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD7YOtzaz6vU"
      },
      "source": [
        "Finally, let's create the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h26aRY9Cn8UJ"
      },
      "outputs": [],
      "source": [
        "fraud_project = client.create_project(name='Credit Card Fraud', use_case=use_case)\n",
        "fraud_project.to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56k6eTyNF3Ci"
      },
      "source": [
        "**Note: When feature_groups_enabled is True then the use case supports feature groups (collection of ML features). Feature groups are created at the organization level and can be tied to a project to further use it for training ML models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmaZ_ME61Cwi"
      },
      "source": [
        "## 2. Add Datasets to your Project\n",
        "\n",
        "Abacus.AI can read datasets directly from `AWS S3` or `Google Cloud Storage` buckets, otherwise you can also directly upload and store your datasets with Abacus.AI. For this workshop, we will have Abacus.AI read the datasets directly from a public S3 bucket's location.\n",
        "\n",
        "We are using one dataset for this notebook. We'll tell Abacus.AI how the dataset should be used when creating it by tagging the dataset with a special Abacus.AI **Dataset Type**.\n",
        "- [Credit Card Fraud Transactions](https://s3.amazonaws.com/realityengines.exampledatasets/fraud_transactions/creditcard.csv) (**TRANSACTIONS**): \n",
        "This dataset contains information about fraud transactions made in the past."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivlmREDM1jF2"
      },
      "source": [
        "### Add the dataset to Abacus.AI\n",
        "\n",
        "First we'll use Pandas to preview the file, then add it to Abacus.AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwu11oqHyFMK"
      },
      "outputs": [],
      "source": [
        "pd.read_csv('https://s3.amazonaws.com/realityengines.exampledatasets/fraud_transactions/creditcard.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLjgvdb31wPS"
      },
      "source": [
        "Using the Create Dataset API, we can tell Abacus.AI the public S3 URI of where to find the datasets. We will also give each dataset a Refresh Schedule, which tells Abacus.AI when it should refresh the dataset (take an updated/latest copy of the dataset).\n",
        "\n",
        "If you're unfamiliar with Cron Syntax, Crontab Guru can help translate the syntax back into natural language: [https://crontab.guru/#0_12_\\*_\\*_\\*](https://crontab.guru/#0_12_*_*_*)\n",
        "\n",
        "**Note: This cron string will be evaluated in UTC time zone**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zbnyhge1yH18"
      },
      "outputs": [],
      "source": [
        "# Add the dataset to Abacus.AI\n",
        "fraud_dataset = client.create_dataset_from_file_connector(name='Credit Card Fraud Transactions', table_name='Credit_Card_Fraud_Transactions',\n",
        "                                     location='s3://realityengines.exampledatasets/fraud_transactions/creditcard.csv',\n",
        "                                     refresh_schedule='0 12 * * *')\n",
        "datasets = [fraud_dataset]\n",
        "for dataset in datasets:\n",
        "    dataset.wait_for_inspection()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnaSh4DyF8uB"
      },
      "source": [
        "## 3. Create Feature Groups and add them to your Project\n",
        "\n",
        "Datasets are created at the organization level and can be used to create feature groups as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wVGiLwZqBAR"
      },
      "outputs": [],
      "source": [
        "feature_group = client.create_feature_group(table_name='transaction_fraud',sql='SELECT * FROM Credit_Card_Fraud_Transactions')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzAFfi6pGQiu"
      },
      "source": [
        "Adding Feature Group to the project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfvRftcmqTeG"
      },
      "outputs": [],
      "source": [
        "client.add_feature_group_to_project(feature_group_id=feature_group.feature_group_id,project_id = fraud_project.project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH5Jp2lSGWrj"
      },
      "source": [
        "Setting the Feature Group type according to the use case requirements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4SQe-6sGW4H"
      },
      "outputs": [],
      "source": [
        "client.set_feature_group_type(feature_group_id=feature_group.feature_group_id, project_id = fraud_project.project_id, feature_group_type= \"TRANSACTIONS\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSeCVN3zGsmb"
      },
      "source": [
        "Check current Feature Group schema:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07HGwMfVqlBp"
      },
      "outputs": [],
      "source": [
        "client.get_feature_group_schema(feature_group_id=feature_group.feature_group_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOhncY5XGwwx"
      },
      "source": [
        "#### For each **Use Case**, there are special **Column Mappings** that must be applied to a column to fulfill use case requirements. We can find the list of available **Column Mappings** by calling the *Describe Use Case Requirements* API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvxohu9GoC9s"
      },
      "outputs": [],
      "source": [
        "client.describe_use_case_requirements(use_case)[0].allowed_feature_mappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5W_z4dJqsoF"
      },
      "outputs": [],
      "source": [
        "client.set_feature_mapping(project_id = fraud_project.project_id,feature_group_id= feature_group.feature_group_id, feature_name='Class',feature_mapping='TARGET')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWRVBhfMHAQW"
      },
      "source": [
        "For each required Feature Group Type within the use case, you must assign the Feature group to be used for training the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHx4lEJApksS"
      },
      "outputs": [],
      "source": [
        "client.use_feature_group_for_training(project_id=fraud_project.project_id, feature_group_id=feature_group.feature_group_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHyyJ9Wmsmsj"
      },
      "source": [
        "Now that we've our feature groups assigned, we're almost ready to train a model!\n",
        "\n",
        "To be sure that our project is ready to go, let's call project.validate to confirm that all the project requirements have been met:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6xJbgRcoETn"
      },
      "outputs": [],
      "source": [
        "fraud_project.validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4zJ4dD1sWjc"
      },
      "source": [
        "## 4. Train a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mZ32i0OsprC"
      },
      "source": [
        "For each **Use Case**, Abacus.AI has a bunch of options for training. We can call the *Get Training Config Options* API to see the available options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQ0h9AKKoFf-"
      },
      "outputs": [],
      "source": [
        "fraud_project.get_training_config_options()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzBf8crhsxB0"
      },
      "source": [
        "In this notebook, we'll just train with the default options, but definitely feel free to experiment, especially if you have familiarity with Machine Learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LUXTTvKoGwt"
      },
      "outputs": [],
      "source": [
        "fraud_model = fraud_project.train_model(training_config={})\n",
        "fraud_model.to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lSL30yms6SP"
      },
      "source": [
        "After we start training the model, we can call this blocking call that routinely checks the status of the model until it is trained and evaluated:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK1fw2aNoI4i"
      },
      "outputs": [],
      "source": [
        "fraud_model.wait_for_evaluation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcAlF1ISHMES"
      },
      "source": [
        "**Note that model training might take some minutes to some hours depending upon the size of datasets, complexity of the models being trained and a variety of other factors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzmH9_Qvs-bY"
      },
      "source": [
        "## **Checkpoint** [Optional]\n",
        "As model training can take an hours to complete, your page could time out or you might end up hitting the refresh button, this section helps you restore your progress:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlVf0fZgtDbN"
      },
      "outputs": [],
      "source": [
        "!pip install abacusai\n",
        "import pandas as pd\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=2)\n",
        "api_key = ''  #@param {type: \"string\"}\n",
        "from abacusai import ApiClient\n",
        "client = ApiClient(api_key)\n",
        "fraud_project = next(project for project in client.list_projects() if project.name == 'Credit Card Fraud Transactions')\n",
        "fraud_model = fraud_project.list_models()[-1]\n",
        "fraud_model.wait_for_evaluation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQcbadWltWsJ"
      },
      "source": [
        "## Evaluate your Model Metrics\n",
        "\n",
        "After your model is done training you can inspect the model's quality by reviewing the model's metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOa3ct8doKe4"
      },
      "outputs": [],
      "source": [
        "pp.pprint(fraud_model.get_metrics().to_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCG6cwhetZ2g"
      },
      "source": [
        "To get a better understanding on what these metrics mean, visit our [documentation](https://abacus.ai/app/help/useCases/FRAUD_ACCOUNT/training) page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8YGFS-SwOdh"
      },
      "source": [
        "## 5. Deploy Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNP84bjDwPEw"
      },
      "source": [
        "After the model has been trained, we need to deploy the model to be able to start making predictions. Deploying a model will reserve cloud resources to host the model for Realtime and/or batch predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7xdUZvXoLm-"
      },
      "outputs": [],
      "source": [
        "fraud_deployment = client.create_deployment(name='Credit Card Fraud Deployment',description='Credit Card Fraud Deployment',model_id=fraud_model.model_id)\n",
        "fraud_deployment.wait_for_deployment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVcCSqF1wWBO"
      },
      "source": [
        "After the model is deployed, we need to create a deployment token for authenticating prediction requests. This token is only authorized to predict on deployments in this project, so it's safe to embed this token inside of a user-facing application or website. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZxSaipooMWu"
      },
      "outputs": [],
      "source": [
        "deployment_token = fraud_project.create_deployment_token().deployment_token\n",
        "deployment_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7oKzllSwYyw"
      },
      "source": [
        "## 6. Predict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkgSiD_owZYW"
      },
      "source": [
        "Now that you have an active deployment and a deployment token to authenticate requests, you can call the `predict_fraud` command below.\n",
        "\n",
        "This command will return the probability of a transaction being of each class of fraud. The prediction would be perfomed based on previous transaction frauds for credit credit cards with similar IDs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEaCdSSroOKE"
      },
      "outputs": [],
      "source": [
        "ApiClient().predict_fraud(deployment_token=deployment_token, \n",
        "               deployment_id=fraud_deployment.deployment_id, \n",
        "               query_data={\"Time\":37569,\"V1\":-1.9863495,\"V2\":1.6931525,\"V3\":0.6006504,\"V4\":0.33007008,\"V5\":0.6902556,\"V6\":0.20807104,\"V7\":1.169273,\"V8\":-0.7722932})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Transaction Fraud Notebook.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}