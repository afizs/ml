{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDJnyHsATwzH"
      },
      "source": [
        "## How-to guide for Related Items use-case on Abacus.AI platform\n",
        "This notebook provides you with a hands on environment to build a model that suggests related items using the Abacus.AI Python Client Library.\n",
        "\n",
        "We'll be using the [User Item Recommendations](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/user_movie_ratings.csv), [Movie Attributes](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/movies_metadata.csv), and [User Attributes](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/users_metadata.csv) datasets, each of which has information about the user and/or their choice of movies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cNn_EHKWbkG"
      },
      "source": [
        "1. Install the Abacus.AI library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiMF9uCkwiwk"
      },
      "outputs": [],
      "source": [
        "!pip install abacusai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5_X_u8NYFsk"
      },
      "source": [
        "We'll also import pandas and pprint tools for visualization in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEjuioFPwvfZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # A tool we'll use to download and preview CSV files\n",
        "import pprint # A tool to pretty print dictionary outputs\n",
        "pp = pprint.PrettyPrinter(indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfH6B0lOYHqX"
      },
      "source": [
        "2. Add your Abacus.AI [API Key](https://abacus.ai/app/profile/apikey) generated using the API dashboard as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpRTYgT3wxVA"
      },
      "outputs": [],
      "source": [
        "#@title Abacus.AI API Key\n",
        "\n",
        "api_key = ''  #@param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpvhR7-iYKZs"
      },
      "source": [
        "3. Import the Abacus.AI library and instantiate a client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uS3rcY6wyhZ"
      },
      "outputs": [],
      "source": [
        "from abacusai import ApiClient\n",
        "client = ApiClient(api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jeBT9uBYMNO"
      },
      "source": [
        "## 1. Create a Project\n",
        "\n",
        "Abacus.AI projects are containers that have datasets and trained models. By specifying a business **Use Case**, Abacus.AI tailors the deep learning algorithms to produce the best performing model possible for your data.\n",
        "\n",
        "We'll call the `list_use_cases` method to retrieve a list of the available Use Cases currently available on the Abacus.AI platform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CECTDnxdwzha"
      },
      "outputs": [],
      "source": [
        "client.list_use_cases()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIAvuJxmYO4a"
      },
      "source": [
        "In this notebook, we're going to create a model that suggests related items using the User Item Recommendations, Movie Attributes, and User Attributes datasets. The 'USER_RELATED' use case is best tailored for this situation. For the purpose of taking an example, we will use the IMDB movie dataset that has movie metadata, user metadata, and user-movie ratings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMxcAhtsw0xk"
      },
      "outputs": [],
      "source": [
        "#@title Abacus.AI Use Case\n",
        "\n",
        "use_case = 'USER_RELATED'  #@param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATVhWoI5YbBr"
      },
      "source": [
        "By calling the `describe_use_case_requirements` method we can view what datasets are required for this use_case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHBWwIrEw19Y"
      },
      "outputs": [],
      "source": [
        "for requirement in client.describe_use_case_requirements(use_case):\n",
        "  pp.pprint(requirement.to_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ-PIxhFYc2J"
      },
      "source": [
        "Finally, let's create the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CP470Q6Tw5OB"
      },
      "outputs": [],
      "source": [
        "related_items_project = client.create_project(name='Related Movies', use_case=use_case)\n",
        "related_items_project.to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoxojjU6IROU"
      },
      "source": [
        "**Note: When feature_groups_enabled is False then the use case does not support feature groups (collection of ML features). Therefore, Datasets are created at the organization level and tied to a project to further use them for training ML models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdXDn61PYefA"
      },
      "source": [
        "## 2. Add Datasets to your Project\n",
        "\n",
        "Abacus.AI can read datasets directly from `AWS S3` or `Google Cloud Storage` buckets, otherwise you can also directly upload and store your datasets with Abacus.AI. For this notebook, we will have Abacus.AI read the datasets directly from a public S3 bucket's location.\n",
        "\n",
        "We are using three datasets for this notebook. We'll tell Abacus.AI how the datasets should be used when creating it by tagging each dataset with a special Abacus.AI **Dataset Type**.\n",
        "- [User Item Recommendations](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/user_movie_ratings.csv) (**USER_ITEM_INTERACTIONS**): \n",
        "This dataset contains information about multiple users' ratings of movies with specified IDs.\n",
        "- [Movie Attributes](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/movies_metadata.csv) (**CATALOG_ATTRIBUTES**): This dataset contains attributes about movies with specified IDs, such as each movie's name and genre.\n",
        "- [User Attributes](https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/users_metadata.csv) (**USER_ATTRIBUTES**): This dataset contains information about users with specified IDs, such as their age, gender, occupation, and zip code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziXTkDqhawo-"
      },
      "source": [
        "### Add the datasets to Abacus.AI\n",
        "\n",
        "First we'll use Pandas to preview the files, then add them to Abacus.AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OBm5KVHxD-M"
      },
      "outputs": [],
      "source": [
        "pd.read_csv('https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/user_movie_ratings.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTXdaK8ExF-W"
      },
      "outputs": [],
      "source": [
        "pd.read_csv('https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/movies_metadata.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Yg7Ys9TxHLo"
      },
      "outputs": [],
      "source": [
        "pd.read_csv('https://s3.amazonaws.com//realityengines.exampledatasets/user_recommendations/users_metadata.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QCTQIG5a0Tp"
      },
      "source": [
        "Using the Create Dataset API, we can tell Abacus.AI the public S3 URI of where to find the datasets. We will also give each dataset a Refresh Schedule, which tells Abacus.AI when it should refresh the dataset (take an updated/latest copy of the dataset).\n",
        "\n",
        "If you're unfamiliar with Cron Syntax, Crontab Guru can help translate the syntax back into natural language: [https://crontab.guru/#0_12_\\*_\\*_\\*](https://crontab.guru/#0_12_*_*_*)\n",
        "\n",
        "**Note: This cron string will be evaluated in UTC time zone**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmGP4miAxK-r"
      },
      "outputs": [],
      "source": [
        "user_item_dataset = client.create_dataset_from_file_connector(name='User Item Recommendations', table_name='User_Item_Recommendations',\n",
        "                                     location='s3://realityengines.exampledatasets/user_recommendations/user_movie_ratings.csv',\n",
        "                                     refresh_schedule='0 12 * * *')\n",
        "\n",
        "movie_attributes_dataset = client.create_dataset_from_file_connector(name='Movie Attributes', table_name='Movie_Attributes',\n",
        "                                     location='s3://realityengines.exampledatasets/user_recommendations/movies_metadata.csv',\n",
        "                                     refresh_schedule='0 12 * * *')\n",
        "\n",
        "user_attributes_dataset = client.create_dataset_from_file_connector(name='User Attributes', table_name='User_Attributes',\n",
        "                                     location='s3://realityengines.exampledatasets/user_recommendations/users_metadata.csv',\n",
        "                                     refresh_schedule='0 12 * * *')\n",
        "\n",
        "datasets = [user_item_dataset, movie_attributes_dataset, user_attributes_dataset]\n",
        "\n",
        "for dataset in datasets:\n",
        "    dataset.wait_for_inspection()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDTfJwE0a4jz"
      },
      "source": [
        "## 3. Create Feature Groups and add them to your Project\n",
        "\n",
        "Datasets are created at the organization level and can be used to create feature groups as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXLqYPEgxL2k"
      },
      "outputs": [],
      "source": [
        "feature_group = client.create_feature_group(table_name='Related_Items1',sql='select * from User_Item_Recommendations')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO5_Xkgu5KBX"
      },
      "source": [
        "Adding Feature Group to the project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkbDGJWU5KBX"
      },
      "outputs": [],
      "source": [
        "client.add_feature_group_to_project(feature_group_id=feature_group.feature_group_id,project_id = related_items_project.project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5149wNGR5KBX"
      },
      "source": [
        "Setting the Feature Group type according to the use case requirements:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQNmV5l65KBX"
      },
      "outputs": [],
      "source": [
        "client.set_feature_group_type(feature_group_id=feature_group.feature_group_id, project_id = related_items_project.project_id, feature_group_type= \"USER_ITEM_INTERACTIONS\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4b-k2pd5KBX"
      },
      "source": [
        "Check current Feature Group schema:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rkl_HqUG5KBX"
      },
      "outputs": [],
      "source": [
        "client.get_feature_group_schema(feature_group_id=feature_group.feature_group_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POJdjIRQ5KBX"
      },
      "source": [
        "#### For each **Use Case**, there are special **Column Mappings** that must be applied to a column to fulfill use case requirements. We can find the list of available **Column Mappings** by calling the *Describe Use Case Requirements* API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lJ7MtLFxO6Q"
      },
      "outputs": [],
      "source": [
        "client.describe_use_case_requirements(use_case)[0].allowed_feature_mappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6zjoayf5KBY"
      },
      "outputs": [],
      "source": [
        "client.set_feature_mapping(project_id=related_items_project.project_id, feature_group_id= feature_group.feature_group_id, feature_name='movie_id', feature_mapping='ITEM_ID')\n",
        "client.set_feature_mapping(project_id=related_items_project.project_id, feature_group_id= feature_group.feature_group_id,feature_name='user_id', feature_mapping='USER_ID')\n",
        "client.set_feature_mapping(project_id=related_items_project.project_id, feature_group_id= feature_group.feature_group_id,feature_name='timestamp', feature_mapping='TIMESTAMP')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJehFqjrJn6A"
      },
      "source": [
        "For each required Feature Group Type within the use case, you must assign the Feature group to be used for training the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKIhnmyx5KBY"
      },
      "outputs": [],
      "source": [
        "client.use_feature_group_for_training(project_id=related_items_project.project_id, feature_group_id=feature_group.feature_group_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvjFCXlIbHoo"
      },
      "source": [
        "Now that we've our feature groups assigned, we're almost ready to train a model!\n",
        "\n",
        "To be sure that our project is ready to go, let's call project.validate to confirm that all the project requirements have been met:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwzR_hL9xRef"
      },
      "outputs": [],
      "source": [
        "related_items_project.validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExtgtxBWbGTa"
      },
      "source": [
        "## 4. Train a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKtExRakbJne"
      },
      "source": [
        "For each **Use Case**, Abacus.AI has a bunch of options for training. We can call the *Get Training Config Options* API to see the available options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ06Ya8LxX_y"
      },
      "outputs": [],
      "source": [
        "related_items_project.get_training_config_options()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX7JSKz1bLQb"
      },
      "source": [
        "In this notebook, we'll just train with the default options, but definitely feel free to experiment, especially if you have familiarity with Machine Learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEuiL5eMxbDc"
      },
      "outputs": [],
      "source": [
        "related_items_model = related_items_project.train_model(training_config={})\n",
        "related_items_model.to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iT1sUz8bNGD"
      },
      "source": [
        "After we start training the model, we can call this blocking call that routinely checks the status of the model until it is trained and evaluated:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iz4TrVRSxfM5"
      },
      "outputs": [],
      "source": [
        "related_items_model.wait_for_evaluation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBGMfuzzKMpG"
      },
      "source": [
        "**Note that model training might take some minutes to some hours depending upon the size of datasets, complexity of the models being trained and a variety of other factors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6VCodv_bOz9"
      },
      "source": [
        "## **Checkpoint** [Optional]\n",
        "As model training can take an hours to complete, your page could time out or you might end up hitting the refresh button, this section helps you restore your progress:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlHo6WVybQLd"
      },
      "outputs": [],
      "source": [
        "!pip install abacusai\n",
        "import pandas as pd\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=2)\n",
        "api_key = ''  #@param {type: \"string\"}\n",
        "from abacusai import ApiClient\n",
        "client = ApiClient(api_key)\n",
        "related_items_project = next(project for project in client.list_projects() if project.name == 'Related Movies')\n",
        "related_items_model = related_items_project.list_models()[-1]\n",
        "related_items_model.wait_for_evaluation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuDsPWKzbZm6"
      },
      "source": [
        "## Evaluate your Model Metrics\n",
        "\n",
        "After your model is done training you can inspect the model's quality by reviewing the model's metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aNY2YgSxgNV"
      },
      "outputs": [],
      "source": [
        "pp.pprint(related_items_model.get_metrics().to_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNfUSQnfbd-M"
      },
      "source": [
        "To get a better understanding on what these metrics mean, visit our [documentation](https://abacus.ai/app/help/useCases/USER_RELATED/training) page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odaqa-x5bkh1"
      },
      "source": [
        "## 5. Deploy Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r03sZ3Fcbl65"
      },
      "source": [
        "After the model has been trained, we need to deploy the model to be able to start making predictions. Deploying a model will reserve cloud resources to host the model for Realtime and/or batch predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAfTjP1Cxj3w"
      },
      "outputs": [],
      "source": [
        "related_items_deployment = client.create_deployment(name='Related Items Deployment',description='Related Items Deployment',model_id=related_items_model.model_id)\n",
        "related_items_deployment.wait_for_deployment()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is9wcFfRbnUr"
      },
      "source": [
        "After the model is deployed, we need to create a deployment token for authenticating prediction requests. This token is only authorized to predict on deployments in this project, so it's safe to embed this token inside of a user-facing application or website."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1OV4FE_xppp"
      },
      "outputs": [],
      "source": [
        "deployment_token = related_items_project.create_deployment_token().deployment_token\n",
        "deployment_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3ajlwc7bp30"
      },
      "source": [
        "## 6. Predict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3i8Zn32brT9"
      },
      "source": [
        "Now that you have an active deployment and a deployment token to authenticate requests, you can make the `get_related_items` API call below.\n",
        "\n",
        "This command will return a list of related items based on the provided user_id (1) and movie_id (466). The related items list would be determined based on what movies the user liked in the past and how the movies and users are related to each other depending on their attributes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TaN_S_fxtHh"
      },
      "outputs": [],
      "source": [
        "ApiClient().get_related_items(deployment_token=deployment_token,\n",
        "               deployment_id=related_items_deployment.deployment_id,\n",
        "               query_data={\"user_id\":\"1\",\"movie_id\":\"466\"})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Related Items Notebook.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}